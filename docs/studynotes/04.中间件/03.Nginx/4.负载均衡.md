---
title: 负载均衡
date: 2023-01-29 15:43:32
permalink: /pages/6fc6c4/
categories:
  - studynotes
  - 中间件
  - Nginx
tags:
  - Nginx
author: 
  name: Xuan
  link: https://github.com/Sidney-Su
---
# Nginx负载均衡

> 负载均衡是实际开发必须掌握的技能，Nginx 如何将少数请求跟多台服务器进行沟通，让每一台服务器的请求处理面面俱到？本内容将学习 Nginx 的负载均衡知识。

## 负载均衡概述

早期的网站流量和业务功能都比较简单，单台服务器足以满足基本的需求，但是随着互联网的发展，业务流量越来越大并且业务逻辑也跟着越来越复杂，单台服务器的性能及单点故障问题就凸显出来了，因此需要多台服务器进行性能的水平扩展及避免单点故障出现。那么如何将不同用户的请求流量分发到不同的服务器上呢？

![1591631182469](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1591631182469.png)



## 负载均衡的原理及处理流程

系统的扩展可以分为纵向扩展和横向扩展。

- 纵向扩展是从单机的角度出发，通过增加系统的硬件处理能力来提升服务器的处理能力
  - 一台服务器无论怎么扩展，总会有上限

- 横向扩展是通过添加机器来满足大型网站服务的处理能力。

![1584602513812](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/image1xwd1pm6du68.webp)

这里面涉及到两个重要的角色分别是"应用集群"和"负载均衡器"。

- 应用集群：将同一应用部署到多台机器上，组成处理集群，接收负载均衡设备分发的请求，进行处理并返回响应的数据。

- 负载均衡器：**将用户访问的请求根据对应的负载均衡算法，分发到集群中的一台服务器进行处理**。



### 负载均衡的作用

1、解决服务器的高并发压力，提高应用程序的处理性能。

2、提供故障转移，实现高可用。

3、通过添加或减少服务器数量，增强网站的可扩展性。

4、在负载均衡器上进行过滤，可以提高系统的安全性。



## 负载均衡常用的处理方式

先说明，我们常用的是 [四/七层负载均衡](https://frxcat.fun/middleware/Nginx/Nginx_load_balancing/#四-七层负载均衡) 方式，前面两个方式可以了解。

#### 方式一:用户手动选择

这种方式比较原始，只要实现的方式就是在网站主页上面提供不同线路、不同服务器链接方式，让用户来选择自己访问的具体服务器，来实现负载均衡。

如下图，用户点击不同的下载方式，就会跳转到不同的下载地址。这是主动式的负载均衡，我们无法控制用户的选择。如果用户全部点击第一个下载方式，那么服务器的压力将非常大。（每个链接对应不同服务器）

![1584602887881](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1584602887881.png)

#### 方式二:DNS轮询方式

DNS：域名系统（服务）协议（DNS）是一种分布式网络目录服务，主要**用于域名与 IP 地址的相互转换**。

大多域名注册商都支持对同一个主机名添加多条A记录(即一个域名可以绑定多个IP地址)，这就是DNS轮询，DNS服务器将解析请求按照A记录的顺序，随机分配到不同的IP上，这样就能完成简单的负载均衡。DNS轮询的成本非常低，在一些不重要的服务器，被经常使用。

如下图：客户端如果想访问服务器集群，首先去 DNS 服务器获取我们曾经在 DNS 服务器保存的「记录表」，这个「记录表」将会把某个服务器的地址返回给客户端，客户端再根据这个地址，访问指定的服务器。这个「记录表」在开始期间需要我们去 DNS 服务器进行添加。

![1591010973996](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1591010973996.png)



「记录表」长什么样，如下图的主机记录 www。这是我们为某一个域名添加的 IP 地址，用 2 台服务器来做负载均衡。其中两个记录值都绑定了 `www.nginx521.cn` 地址。(一个域名可以绑定多个IP地址)

![1590064506355](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1590064506355.png)



验证:

```sh
ping www.nginx521.cn # 会缓存这个域名与IP对应关系
```

注意：记得清空本地的 DNS 缓存，如果本地有缓存，无论你怎么 `ping`，都会 `ping` 到缓存的服务器地址，无法负载均衡

> 为了提高dns域名解析速度，一般我们会在本地缓存dns解析结果，即本地会缓存这个IP与域名的绑定关系，先去缓存中找
>
> 目前需要 `ping` 一次然后清理一次缓存，才能实现负载均衡的轮询效果。

```sh
ipconfig/flushdns #清空本地的dns缓存
```

我们发现使用DNS来实现轮询，不需要投入过多的成本，虽然DNS轮询成本低廉，但是DNS负载均衡存在明显的缺点。

1.可靠性低

假设一个域名DNS轮询多台服务器，如果其中的一台服务器发生故障，那么所有的访问该服务器的请求将不会有所回应，即使你将该服务器的IP从DNS中去掉，但是由于各大宽带接入商将众多的DNS存放在缓存中，以节省访问时间，导致DNS不会实时更新。所以DNS轮流上一定程度上解决了负载均衡问题，但是却存在可靠性不高的缺点。

2.负载均衡不均衡

DNS负载均衡采用的是简单的轮询负载算法，不能区分服务器的差异，不能反映服务器的当前运行状态，不能做到为性能好的服务器多分配请求，另外本地计算机也会缓存已经解析的域名到IP地址的映射，这也会导致使用该DNS服务器的用户在一定时间内访问的是同一台Web服务器，从而引发Web服务器减的负载不均衡。

负载不均衡则会导致某几台服务器负荷很低，而另外几台服务器负荷确很高，处理请求的速度慢，配置高的服务器分配到的请求少，而配置低的服务器分配到的请求多。



#### 方式三:四/七层负载均衡

介绍四/七层负载均衡之前，我们先了解一个概念，OSI(open system interconnection)，叫开放式系统互联模型，这个是由国际标准化组织 ISO 指定的一个不基于具体机型、操作系统或公司的网络体系结构。该模型将网络通信的工作分为七层。

![](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/image6uq265ihol80.webp)

- 应用层：为应用程序提供网络服务。
- 表示层：对数据进行格式化、编码、加密、压缩等操作
- 会话层：建立、维护、管理会话连接
- 传输层：建立、维护、管理端到端的连接，常见的有 TCP/UDP
- 网络层：IP 寻址和路由选择
- 数据链路层：控制网络层与物理层之间的通信
- 物理层：比特流传输

所谓**四层负载均衡**指的是OSI七层模型中的传输层，主要是**基于 IP+PORT 的负载均衡**

```properties
实现四层负载均衡的方式：
	硬件：F5 BIG-IP、Radware等（优：性能好 缺：成本高、不能自行扩展）
	软件：LVS、Nginx、Hayproxy等（优：成本低、可扩展性强 缺：性能没硬件好）
```

所谓的**七层负载均衡**指的是在应用层，主要是**基于虚拟的URL或主机IP的负载均衡**

```properties
实现七层负载均衡的方式：
	软件：Nginx、Hayproxy等
```

四层和七层负载均衡的区别

- 四层负载均衡数据包是在底层就进行了分发，而七层负载均衡数据包则在最顶端进行分发，所以四层负载均衡的效率比七层负载均衡的要高。
- 四层负载均衡不识别域名，而七层负载均衡识别域名。

除了四层和七层负载以外，其实还有二层、三层负载均衡，二层是在数据链路层基于mac地址来实现负载均衡，三层是在网络层一般采用虚拟IP地址的方式实现负载均衡。（二、三用的少）

**实际环境采用的模式：四层负载(LVS)+七层负载(Nginx)**





### Nginx七层负载均衡

Nginx要实现七层负载均衡需要用到proxy_pass代理模块配置。Nginx默认安装支持这个模块，我们不需要再做任何处理。Nginx的负载均衡是在Nginx的反向代理基础上把用户的请求根据指定的算法分发到一组【upstream虚拟服务池】。

#### Nginx七层负载均衡的指令

##### upstream指令

该指令是用来定义一组服务器，它们可以是监听不同端口的服务器，并且也可以是同时监听TCP和Unix socket的服务器。服务器可以指定不同的权重，默认为1。

| 语法   | upstream name {...} |
| ------ | ------------------- |
| 默认值 | —                   |
| 位置   | http                |



##### server指令

该指令用来指定后端服务器的名称和一些参数，可以使用域名、IP、端口或者Unix socket

| 语法     | server name [paramerters] |
| -------- | ------------------------- |
| 默认值   | —                         |
| **位置** | **upstream**              |

server 后的 name 就是 upstream 后的 name，两者保持一致。



#### Nginx七层负载均衡的实现流程

准备四台服务器，一台用来做负载均衡器，三台用来接收负载均衡器的请求。

![1590248160635](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1590248160635.png)

因为目前只有两台服务器，所以一台用来做负载均衡器，另外一台用来接收负载均衡器的请求。

服务器设置：这里以三个端口代替三个服务器，在配置文件进行如下配置：

```nginx
server {
    listen   9001;
    server_name localhost;
    default_type text/html;
    location /{
    	return 200 '<h1>192.168.200.146:9001</h1>';
    }
}
server {
    listen   9002;
    server_name localhost;
    default_type text/html;
    location /{
    	return 200 '<h1>192.168.200.146:9002</h1>';
    }
}
server {
    listen   9003;
    server_name localhost;
    default_type text/html;
    location /{
    	return 200 '<h1>192.168.200.146:9003</h1>';
    }
}
```

负载均衡器设置：这是一个 Nginx 代理服务器，让它去负载均衡访问三个服务器，在配置文件进行如下配置：

```nginx
upstream backend{
	server 192.168.200.146:9091;
	server 192.168.200.146:9092;
	server 192.168.200.146:9093;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend; # backend 要对应上 upstream 后的值，根据需求修改
	}
}
```

访问负载均衡器的地址，如 `http://192.168.200.133:8083`，它会找到 `proxy_pass` 后的地址，比如上方，它会根据 backend 找到对应的 upstream 里内地址，替换掉 backend，变成：

- proxy_pass `http://192.168.200.146:9091`
- proxy_pass `http://192.168.200.146:9092`
- proxy_pass `http://192.168.200.146:9093`

但是它不会全部访问三个服务器地址，而是根据自己的算法（轮询）选择其中一个服务器地址。



#### 负载均衡状态

代理服务器在负责均衡调度中的状态有以下几个：

| 状态         | 概述                              |
| ------------ | --------------------------------- |
| down         | 当前的server暂时不参与负载均衡    |
| backup       | 预留的备份服务器                  |
| max_fails    | 允许请求失败的次数                |
| fail_timeout | 经过max_fails失败后, 服务暂停时间 |
| max_conns    | 限制最大的接收连接数              |

> 一般 max_fails+fail_timeout 配合使用

##### down

`down`将该服务器标记为永久不可用，那么该代理服务器将不参与负载均衡。

如下，如果不希望负载均衡器以负载均衡来处理 `192.168.200.146` 服务器：

```nginx
upstream backend{
	server 192.168.200.146:9001 down; #标识此服务已宕机，不会参与负载
	server 192.168.200.146:9002
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

该状态一般会对需要停机维护的服务器进行设置。



##### backup

`backup`将该服务器标记为备份服务器，当主服务器不可用时，才用备份服务器来传递请求。

它不同于 down 指令，down 指令将服务器永久禁止，而 backp 指令仅仅临时禁止，当主服务器不可用后，临时禁止的服务器就会站出来。

```nginx
upstream backend{
	server 192.168.200.146:9001 down; # 宕机，不接收用户请求
	server 192.168.200.146:9002 backup; # 当主服务器挂了，我就接收用户请求。当主服务器恢复后，我继续当备份，主服务器继续提供服务
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

上方代码中 9001 服务器永久禁止，而 9002 服务器是备份服务器，所以 9003 服务器是主服务器。

此时需要将9094端口的访问禁止掉来模拟下唯一能对外提供访问的服务宕机以后，backup的备份服务器就要开始对外提供服务，此时为了测试验证，我们需要使用防火墙来进行拦截。



介绍一个工具`firewall-cmd`，该工具是Linux提供的专门用来操作firewall的。（firewall就是防火墙）

```sh
systemctl start firewalld #打开防火墙
```

查询防火墙中指定的端口是否开放

```sh
firewall-cmd --query-port=9001/tcp
```

如何开放一个指定的端口

```sh
# --permanent永久开放，不加就是临时开放
firewall-cmd --permanent --add-port=9002/tcp
```

批量添加开放端口

```sh
firewall-cmd --permanent --add-port=9001-9003/tcp
```

如何移除一个指定的端口

```sh
firewall-cmd --permanent --remove-port=9003/tcp
```

重新加载（每次修改都需要重新加载）

```sh
firewall-cmd --reload
```

其中

- `--permanent` 表示设置为持久
- `--add-port` 表示添加指定端口
- `--remove-port` 表示移除指定端口

经过测试，禁用掉 9003 端口后，再次访问负载均衡器，它只会请求 9002 端口的服务器(备份服务器)；而恢复 9003 端口，只会请求 9003 端口的服务器。



##### max_conns

`max_conns=number`：用来设置代理服务器同时活动链接的最大数量，默认为0，表示不限制，使用该配置可以根据后端服务器处理请求的并发量来进行设置，防止后端服务器被压垮。

| 语法             | 默认值 | 位置     |
| ---------------- | ------ | -------- |
| max_conns=number | 0      | upstream |

number 是大于 0 的数字。

```nginx
upstream backend{
	server 192.168.200.146:9001 down;
	server 192.168.200.146:9002 backup;
	server 192.168.200.146:9003 max_conns=2;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

第 4 行配置标识 9003 端口的服务器最大能被 2 个客户端请求。



##### max_fails和fail_timeout

`max_fails=number`设置允许请求代理服务器失败的次数，默认为1。

`fail_timeout=time`设置经过max_fails失败后，服务暂停的时间，默认是10秒。

| 语法              | 默认值 | 位置     |
| ----------------- | ------ | -------- |
| max_fails=number  | 1      | upstream |
| fail_timeout=time | 10 秒  | upstream |

- number 是大于 0 的数字
- time 是时间，单位为秒

```nginx
upstream backend{
	server 192.168.200.133:9001 down;
	server 192.168.200.133:9002 backup;
	server 192.168.200.133:9003 max_fails=3 fail_timeout=15; #当此服务器出问题后，再次访问肯定会失败，如果访问失败次数达到了3次 就会触发第二个条件。也就是15s内不能再次被使用，哪怕15s内此服务器再次恢复正常也没用。15s后会查看此服务器有无恢复，若无恢复，备份服务器顶上
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```



#### 负载均衡策略

介绍完Nginx负载均衡的相关指令后，我们已经能实现将用户的请求分发到不同的服务器上，那么除了采用默认的分配方式以外，我们还能采用什么样的负载算法?

Nginx的upstream支持如下六种方式的分配算法，分别是:

| 算法名称   | 说明             |
| ---------- | ---------------- |
| 轮询       | 默认方式         |
| weight     | 权重方式         |
| ip_hash    | 依据ip分配方式   |
| least_conn | 依据最少连接方式 |
| url_hash   | 依据URL分配方式  |
| fair       | 依据响应时间方式 |

##### 轮询

是`upstream`模块负载均衡默认的策略。每个请求会按时间顺序逐个分配到不同的后端服务器。轮询不需要额外的配置。

```nginx
upstream backend{
	server 192.168.200.146:9001 weight=1; # 权重默认为1
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```



##### weight加权[加权轮询]

`weight=number`用来设置服务器的权重，默认为1，权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的，所有此策略比较适合服务器的硬件配置差别比较大的情况。

| 语法          | 默认值 | 位置     |
| ------------- | ------ | -------- |
| weight=number | 1      | upstream |

- number 是大于 0 的数字

```nginx
upstream backend{
	server 192.168.200.146:9001 weight=10;
	server 192.168.200.146:9002 weight=5;
	server 192.168.200.146:9003 weight=3;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```



##### ip_hash

> 根据客户端IP固定分发到某个服务器

当对后端的多台动态应用服务器做负载均衡时，`ip_hash`指令能够将某个客户端IP的请求通过哈希算法定位到同一台后端服务器上。这样，当来自某一个IP的用户在后端Web服务器A上登录后，在访问该站点的其他URL，能保证其访问的还是后端web服务器A。

总结：哪个服务器曾经处理过请求，无论在哪里，相同的请求依然让该服务器处理

| 语法   | ip_hash; |
| ------ | -------- |
| 默认值 | —        |
| 位置   | upstream |

```nginx
upstream backend{
	ip_hash;
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

需要额外多说一点的是使用ip_hash指令无法保证后端服务器的负载均衡，可能导致有些后端服务器接收到的请求多，有些后端服务器接收的请求少，而且设置后端服务器权重等方法将不起作用。（不建议使用）

![1591706748677](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1591706748677.png)

> 可以用`ip_hash`解决session不共享的问题；也可以使用redis解决session不共享的问题



##### least_conn

最少连接，把请求转发给连接数较少的后端服务器。轮询算法是把请求平均的转发给各个后端，使它们的负载大致相同；但是，有些请求占用的时间很长，会导致其所在的后端负载较高。这种情况下，`least_conn`这种方式就可以达到更好的负载均衡效果。

```nginx
upstream backend{
	least_conn;
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

**此负载均衡策略适合请求处理时间长短不一造成服务器过载的情况**。

![1591809623736](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1591809623736.png)

##### url_hash

> 根据客户端访问的url固定分发到某个服务器

按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，要配合缓存命中来使用。

同一个资源多次请求，可能会到达不同的服务器上，导致不必要的多次下载，缓存命中率不高，以及一些资源时间的浪费。而使用`url_hash`，可以使得同一个url（也就是同一个资源请求）会到达同一台服务器，一旦缓存住了资源，再此收到请求，就可以从缓存中读取。

总结：发送相同的请求时，希望只有一个服务器处理该请求，使用 `uri_hash`。因为 URL 相同，则哈希值(hash)相同，那么哈希值对应的服务器也相同。

```nginx
upstream backend{
	hash $request_uri; # $request_uri是nginx的内置变量，获取请求的uri地址
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

访问如下地址：

```http
http://192.168.200.133:8083/a
http://192.168.200.133:8083/b
http://192.168.200.133:8083/c
```

如图：文件系统有一个文件，目前只有 web 服务 1 和服务 3 获取了该文件，那么我们想要下载这个文件时，只能找服务 1 或服务 3，这时候就固定一个 URL，该 URL 不允许服务 2 进行处理，那么如何规定哪个服务处理呢？就用到 `url_hash`。

它会根据 URL 计算处哈希值，由哈希值对应服务，所以固定下载文件的 URL，就固定了一个服务处理。

![1591812222306](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1591812222306.png)

> 文件系统的某个文件只存在于服务1和服务3，用户通过url获取此文件。如果每次都需要服务请求文件系统拿文件过于麻烦，我们可以将文件缓存在服务中，此时就会出现问题：如果负载均衡到了服务2 就会找不到这个文件，所以我们需要固定url访问特定的服务
>
> 访问同一个文件，url肯定是固定的



##### fair

`fair`采用的不是内建负载均衡使用的轮换的均衡算法，而是可以根据页面大小、加载时间长短智能的进行负载均衡。那么如何使用第三方模块的`fair`负载均衡策略？

```nginx
upstream backend{
	fair;
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

但是如何直接使用会报错，因为fair属于第三方模块实现的负载均衡。需要添加`nginx-upstream-fair`，如何添加对应的模块：

==（注意：真实配置自己看视频摸索一下，下面的配置我跟着讲师与博客上的都摘录了一点）==

1\. 下载`nginx-upstream-fair`模块，下载地址如下：

```http
https://github.com/gnosek/nginx-upstream-fair
```

2\. 将下载的文件上传到服务器并进行解压缩

```sh
# 进入安装包目录
cd /opt

# 解压
unzip nginx-upstream-fair-master.zip
```

3\. 重命名资源

```sh
mv nginx-upstream-fair-master fair
```

4\. 将原有 `/usr/local/nginx/sbin/nginx` 进行备份

```sh
mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.backup
```

5\. 查看 `configure arguments` 的配置信息，拷贝出来

```sh
nginx -V

# 拷贝 configure arguments 后面的数据
```

6\. 进入 Nginx 的安装目录，执行 make clean 清空之前编译的内容

```sh
cd /root/nginx/core/nginx-1.21.6

make clean
```

7\. 使用./configure命令将资源添加到Nginx模块中，记得加上第（4）步拷贝的配置信息

```sh
./configure --add-module=/root/fair # 记得添加 configure arguments 后的数据
```

8\. 通过 make 模板进行编译

```sh
make
```

编译可能会出现如下错误，`ngx_http_upstream_srv_conf_t`结构中缺少`default_port`

![1584941470457](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1584941470457.png)



解决方案:

在Nginx的源码目录（安装包目录）中 `src/http/ngx_http_upstream.h`，找到`ngx_http_upstream_srv_conf_s`，在模块中添加添加`default_port`属性

```sh
vim /opt/nginx/core/nginx-1.21.6/src/http/ngx_http_upstream.h
```

添加内容：

```sh
in_port_t	   default_port
```

![1584943399597](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1584943399597.png)

然后再进行make.

9\. 更新Nginx

- 
  将sbin目录下的nginx进行备份


```sh
mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginxold
```

- 将安装目录下的objs中的nginx拷贝到sbin目录


```sh
cd /opt/nginx/core/nginx-1.21.6/objs
cp nginx /usr/local/nginx/sbin
```

- 更新Nginx


```sh
cd /opt/nginx/core/nginx-1.21.6
make upgrade #热部署、在线升级
```

10\. 编译测试使用Nginx

上面介绍了Nginx常用的负载均衡的策略，有人说是5种，是把轮询和加权轮询归为一种，也有人说是6种。那么在咱们以后的开发中到底使用哪种，这个需要根据实际项目的应用场景来决定的。



#### 负载均衡案例

##### 案例一：对所有请求实现一般轮询规则的负载均衡

```nginx
upstream backend{
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```



##### 案例二：对所有请求实现加权轮询规则的负载均衡

```nginx
upstream backend{
	server 192.168.200.146:9001 weight=7;
	server 192.168.200.146:9002 weight=5;
	server 192.168.200.146:9003 weight=3;
}
server {
	listen 8083;
	server_name localhost;
	location /{
		proxy_pass http://backend;
	}
}
```

处理请求概率：9001 端口 > 9003 端口 > 9002 端口



##### 案例三：对特定资源实现负载均衡

```nginx
upstream videobackend{
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
}
upstream filebackend{
	server 192.168.200.146:9003;
	server 192.168.200.146:9004;
}
server {
	listen 8084;
	server_name localhost;
	location /video/ {
		proxy_pass http://videobackend;
	}
	location /file/ {
		proxy_pass http://filebackend;
	}
}
```

发送 `/video/` 请求会被 9001 和 9002 端口的服务器处理。

发送 `/file/` 请求会被 9003 和 9004 端口的服务器处理。



##### 案例四：对不同域名实现负载均衡

```nginx
upstream itcastbackend{
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
}
upstream itheimabackend{
	server 192.168.200.146:9003;
	server 192.168.200.146:9004;
}
server {
	listen	8085;
	server_name www.frx.com;
	location / {
		proxy_pass http://itcastbackend;
	}
}
server {
	listen	8086;
	server_name www.itheima.cn;
	location / {
		proxy_pass http://itheimabackend;
	}
}
```

`www.frx.com` 地址的请求由 9001 端口和 9002 端口处理。

`www.itheima.cn` 地址的请求由 9003 端口和 9004 端口处理。



##### 案例五：实现带有URL重写的负载均衡

```nginx
upstream backend{
	server 192.168.200.146:9001;
	server 192.168.200.146:9002;
	server 192.168.200.146:9003;
}
server {
	listen	80;
	server_name localhost;
	location /file/ {
        # $1拿到的是()里面的内容
		rewrite ^(/file/.*) /server/$1 last; #last会拿着你重写的url重新匹配
	}
	location /server { #然后就被分发到了这里
		proxy_pass http://backend;
	}
}
```

将 `/file/xxx` 请求重写为 `/server/xxx`，然后触发 `location /server`，实现负载均衡。

此时被负载均衡的服务器地址也会带有 `/server` 以及后面的参数，如 `192.168.200.146:9001/server/xxx`





### Nginx四层负载均衡

Nginx在1.9之后，增加了一个stream模块，用来实现四层协议的转发、代理、负载均衡等。stream模块的用法跟http的用法类似，允许我们配置一组TCP或者UDP等协议的监听，然后通过proxy_pass来转发我们的请求，通过upstream添加多个后端服务，实现负载均衡。

四层协议负载均衡的实现，一般都会用到LVS、HAProxy、F5等，要么很贵要么配置很麻烦，而Nginx的配置相对来说更简单，更能快速完成工作。(但其实用nginx作为四层负载使用不多)

#### 添加stream模块的支持

Nginx默认是没有编译这个模块的，需要使用到stream模块，那么需要在编译的时候加上`--with-stream`。

完成添加`--with-stream`的实现步骤：

- 将原有 `/usr/local/nginx/sbin/nginx` 进行备份
- 拷贝 `Nginx -V` 的 configure arguments 配置信息
- 在 Nginx 的安装源码进行配置指定对应模块：`./configure --with-stream 加上一步拷贝的configure arguments 配置`
- 通过 make 模板进行编译
- 将 objs 下面的 nginx 移动到 `/usr/local/nginx/sbin` 下
- 在源码目录下执行 `make upgrade` 进行升级，这个可以实现不停机添加新模块的功能

添加模块的详细步骤我已经在 [七层负载均衡策略-fail 指令](https://frxcat.fun/middleware/Nginx/Nginx_load_balancing/)、[静态资源部署-Nginx 模块添加](https://frxcat.fun/middleware/Nginx/Nginx_Static_resource_deployment/#nginx模块添加)、[反向代理-添加ssl支持](https://frxcat.fun/middleware/Nginx/Nginx_Reverse_proxy/#添加ssl支持) 描述过，而你只需要替换模块名字罢了。



#### Nginx四层负载均衡的指令

如果不想在 http 模块使用负载均衡，可以在 steam 模块使用。

##### stream指令

该指令提供在其中指定流服务器指令的配置文件上下文。和http指令同级。

| 语法   | stream { ... } |
| ------ | -------------- |
| 默认值 | —              |
| 位置   | main           |

```nginx
http {
    server {
        listen 80;
        # ......
    }
}
stream {
    upstream backend{
        server 192.168.200.146:6379;
        server 192.168.200.146:6378;
    }
    server {
        listen 81;
        proxy_pass backend;
    }
}
```

##### upstream指令

该指令和http的upstream指令是类似的。



#### 四层负载均衡的案例

准备两台服务器，这里称为 A 和 B。服务器 A 的 IP 为 `192.168.200.146`，服务器 B 的IP 为 `192.168.200.133`，服务器 A 存放 Redis 和 Tomcat，服务器 B 作为负载均衡器，对服务器 A 的端口进行负载均衡处理。

##### 需求分析

![1591897178807](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1591897178807.png)

**实现步骤**

**Redis配置**

(1)准备 Redis 服务器，在服务器 A 上准备两个 Redis，端口分别是 6379、6378。

1\. 上传redis的安装包，`redis-4.0.14.tar.gz`，这里上传目录是 `/opt`

2\. 将安装包进行解压缩

```sh
tar -zxf redis-4.0.14.tar.gz
```

3\. 进入redis的安装包

```sh
cd redis-4.0.14
```

4\. 使用make和install进行编译和安装，这里的安装路径是 `/usr/local/redis/redis01`

```sh
make PREFIX=/usr/local/redis/redis01 install
```

5\. 拷贝redis配置文件`redis.conf`到`/usr/local/redis/redis01/bin`目录中，因为安装后，目录并没有 redis.conf

```sh
cp /opt/redis-4.0.14/redis.conf	/usr/local/redis/redis01/bin
```

6\. 修改redis.conf配置文件，注意：不是添加内容，是修改内容，要自己搜索 bind、port 和 daemonize 进行修改

```sh
bind 0.0.0.0   # 允许任意地址访问，生产环境千万不要搞这个
port  6379      #redis的端口
daemonize yes   #后台启动redis
```

7\. 将redis01复制一份为redis02

```sh
cd /usr/local/redis
cp -r redis01 redis02
```

8\. 将redis02文件文件夹中的redis.conf进行修改，注意：不是添加内容，是修改内容，要自己搜索 bind、port 和 daemonize 进行修改

```sh
bind 0.0.0.0   # 允许任意地址访问，生产环境千万不要搞这个
port  6378      #redis的端口
daemonize yes   #后台启动redis
```

9\. 分别启动，即可获取两个Redis.并查看

```sh
ps -ef | grep redis
```

使用 Nginx 将请求分发到不同的 Redis 服务器上。

安装 Redis 并验证能启动成功后，在另一台服务器 B `192.168.200.133` 的 Nginx 配置文件添加如下内容：（确保安装了 steam 模块）

```nginx
stream { #配置四层负载均衡
    upstream redisbackend{
        server 192.168.200.146:6379;   # 服务器 B 的 6379 端口
        server 192.168.200.146:6378;   # 服务器 B 的 6378 端口
    }
    server {
        listen 81;
        proxy_pass redisbackend;
    }
}
```

此时利用 redis-cli 连接测试

![image](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/imagecbee2u83yhs.webp)

服务器 B 通过负载均衡连接到了服务器 A 的 Redis，只是不知道连接的是 6378 还是 6379 端口，可以在 Redis 添加不一样的数据来测试，这里不演示了。



**Tomcat配置**

(2)准备Tomcat服务器到服务器A

1\. 上传tomcat的安装包，`apache-tomcat-8.5.56.tar.gz`

2\. 将安装包进行解压缩

```sh
tar -zxf apache-tomcat-8.5.56.tar.gz
```

3\.进入tomcat的bin目录，启动 tomcat

```sh
cd apache-tomcat-8.5.56/bin
./startup
```

服务器 B 的配置文件 nginx.conf 配置如下：

```nginx
stream { #配置四层负载均衡
    upstream redisbackend { #负载到redis
        server 192.168.200.146:6379;    # 服务器 B 的 6379 端口
        server 192.168.200.146:6378;    # 服务器 B 的 6378 端口
    }
    upstream tomcatbackend { #负载到tomcat
        server 192.168.200.146:8080;   # 服务器 B 的 8080 端口
    }
    server {
        listen  81;
        proxy_pass redisbackend; # redis 的负载均衡
    }
    server {
        listen	82;
        proxy_pass tomcatbackend;  # tomcat 的负载均衡
    }
}

```

访问服务器 B 的地址进行测试：`192.168.200.133:82`。先四层负载均衡后七层负载均衡







# Nginx缓存集成

## 缓存的概念

缓存就是数据交换的缓冲区(称作:Cache)，当用户要获取数据的时候，会先从缓存中去查询获取数据，如果缓存中有就会直接返回给用户，如果缓存中没有，则会发请求从服务器重新查询数据，将数据返回给用户的同时将数据放入缓存，下次用户就会直接从缓存中获取数据。

![1591944051969](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1591944051969.png)

缓存其实在很多场景中都有用到，比如：

| 场景             | 作用                     |
| ---------------- | ------------------------ |
| 操作系统磁盘缓存 | 减少磁盘机械操作         |
| 数据库缓存       | 减少文件系统的IO操作     |
| 应用程序缓存     | 减少对数据库的查询       |
| Web服务器缓存    | 减少对应用服务器请求次数 |
| 浏览器缓存       | 减少与后台的交互次数     |

缓存的优点

1. 减少数据传输，节省网络流量，加快响应速度，提升用户体验；

2. 减轻服务器压力；

3. 提供服务端的高可用性；（如果服务出问题了，一部分数据在缓存，缓解运维压力）

缓存的缺点

1. 数据的不一致

2. 增加成本

![1582295367198](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1582295367198.png)

在 [静态资源部署 - 缓存配置](https://frxcat.fun/middleware/Nginx/Nginx_Static_resource_deployment/#静态资源缓存配置) 的时候，我们学习了如何在浏览器进行缓存，而本内容学习的是 Nginx。

本次课程注解讲解的是Nginx，Nginx作为web服务器，Nginx作为Web缓存服务器，它介于客户端和应用服务器之间，当用户通过浏览器访问一个URL时，web缓存服务器会去应用服务器获取要展示给用户的内容，将内容缓存到自己的服务器上，当下一次请求到来时，如果访问的是同一个URL，web缓存服务器就会直接将之前缓存的内容返回给客户端，而不是向应用服务器再次发送请求。web缓存降低了应用服务器、数据库的负载，减少了网络延迟，提高了用户访问的响应速度，增强了用户的体验。



## Nginx的web缓存服务

Nginx是从0.7.48版开始提供缓存功能。Nginx是基于Proxy Store来实现的，**其原理是把URL及相关组合当做Key,在使用MD5算法对Key进行哈希，得到硬盘上对应的哈希目录路径，从而将缓存内容保存在该目录中**。它可以支持任意URL连接，同时也支持404/301/302这样的非200状态码。Nginx即可以支持对指定URL或者状态码设置过期时间，也可以使用purge命令来手动清除指定URL的缓存。

![1591947990200](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1591947990200.png)

> 1.在nginx中拿到url后，可以指定是直接使用`url`作为key或者`url+自定义`作为key；
> 2.对key进行MD5计算
> 3.指定缓存的目录(问题：如果将所有都缓存同一个目录，缓存增多 目录数据越大，一个目录数据过大 目录访问速度非常低。可以使用第二步的密文+第三步的路径组合配置)
> 4.第三步目录/密文截取1/密文截取2(key不一样，MD5计算就不一样，截取的目录也就不一样)
>
> 存在就直接返回，不存在请求后台服务器，然后缓存进行返回
>
> nginx还支持对状态码缓存。假设状态码已经缓存，问题：第一次访问资源不存在响应404，第二次这个资源存在了，用户请求还是走nginx缓存于是响应404。所以我们需要定时清理这些缓存，设置一个过期时间；也可以通过purge命令手动清除指定url或状态码对应的缓存



## Nginx缓存设置的相关指令

Nginx的web缓存服务主要是使用`ngx_http_proxy_module`模块相关指令集来完成，接下来我们把常用的指令来进行介绍下。[ngx_http_proxy_module 文档地址](http://nginx.org/en/docs/http/ngx_http_proxy_module.html)

### proxy_cache_path

**该指定用于设置缓存文件的存放路径**

| 语法   | proxy_cache_path path [levels=number] <br/>keys_zone=zone_name:zone_size [inactive=time]\[max_size=size]; |
| ------ | ------------------------------------------------------------ |
| 默认值 | —                                                            |
| 位置   | http                                                         |

`path`缓存路径地址，如：

```sh
/usr/local/proxy_cache
```



`levels`: 指定该缓存空间 `path` 基础上新建的目录，最多可以设置 3 层，每层取 1 到 2 个字母作为目录名，格式为：(字母名从 MD5 加密的值后面往前截取。)

```nginx
levels=num:num:num   # 三个 num 代表三层，每层目录名分别取 num 个字母
levels=num:num       # 两个 num 代表两层，每层目录名分别取 num 个字母
levels=num           # 一个 num 代表一层，每层目录名分别取 num 个字母
```

示例

```nginx
levels=1:2   #缓存空间有两层目录，第一层目录名取 1 个字母，第二层目录名取 2 个字母。
#举例说明: 假设 proxy_cache_key 为 kele，通过MD5加密以后的值为：43c8233266edce38c2c9af0694e2107d
levels=1:2   #最终的存储路径为/usr/local/proxy_cache/d/07，每层截取个数根据 1:2
levels=2:1:2 #最终的存储路径为/usr/local/proxy_cache/7d/0/21，每层截取个数根据 2:1:2
levels=2:2:2 #最终的存储路径为??/usr/local/proxy_cache/7d/10/e2，每层截取个数根据 2:2:2
```



`keys_zone`用来为这个缓存区设置名称和指定大小，如：

```nginx
keys_zone=itcast:200m  #缓存区的名称是itcast,大小为200M,1M大概能存储8000个keys
```



`inactive`指定缓存的数据多次时间未被访问就将被删除，默认情况下，`inactive` 设置为 10 分钟。如：

```nginx
inactive=1d   #缓存数据在1天内没有被访问就会被删除
```



`max_size`设置最大缓存空间，如果缓存空间存满，默认会覆盖缓存时间最长的资源，默认单位为兆。如:

```nginx
max_size=20g # 最大缓存空间为 20G
```



配置实例:

```nginx
http{
    # 如果这个路径不存在，会帮你自动创建
	proxy_cache_path /usr/local/proxy_cache keys_zone=itcast:200m  levels=1:2:1 inactive=1d max_size=20g;
}
```

此时重启 Nginx 配置文件，发现 `/usr/local` 目录里多出一个目录，名字叫做 proxy_cache。



### proxy_cache

该指令用来开启或关闭代理缓存，如果是开启则自定使用哪个缓存区来进行缓存。默认关闭。

| 语法   | proxy_cache zone_name\|off; |
| ------ | --------------------------- |
| 默认值 | proxy_cache off;            |
| 位置   | http、server、location      |

zone_name：指定使用缓存区的名称

> 注意：缓存区的名称必须是 `proxy_cache_path` 里的 `keys_zone` 生成的缓存名。



### proxy_cache_key

**该指令用来设置web缓存的key值**，Nginx 会根据 key 值利用 MD5 计算处哈希值并缓存起来，作为缓存目录名的参考。默认：`请求协议+代理主机+请求uri`作为key

| 语法   | proxy_cache_key key;                              |
| ------ | ------------------------------------------------- |
| 默认值 | proxy_cache_key \$scheme\$proxy_host$request_uri; |
| 位置   | http、server、location                            |

如 kele 由 MD5 计算出来是 27ce47ea65c1381dbe5175f7c77d8a3a

在哪计算出来的？ 前往 [MD5 在线加密网站](https://md5jiami.bmcx.com/)



### proxy_cache_valid

该指令用来对不同返回状态码的URL设置不同的缓存时间

| 语法   | proxy_cache_valid [code ...] time; |
| ------ | ---------------------------------- |
| 默认值 | —                                  |
| 位置   | http、server、location             |

如：

```nginx
proxy_cache_valid 200 302 10m;
proxy_cache_valid 404 1m;
# 为200和302的响应URL设置10分钟缓存，为404的响应URL设置1分钟缓存
proxy_cache_valid any 1m;
# 对所有响应状态码的URL都设置1分钟缓存
```



### proxy_cache_min_uses

该指令用来设置资源被访问多少次后被缓存。默认是 1 次。

| 语法   | proxy_cache_min_uses number; |
| ------ | ---------------------------- |
| 默认值 | proxy_cache_min_uses 1;      |
| 位置   | http、server、location       |



### proxy_cache_methods

该指令用户设置缓存哪些HTTP方法

| 语法   | proxy_cache_methods GET\|HEAD\|POST; |
| ------ | ------------------------------------ |
| 默认值 | proxy_cache_methods GET HEAD;        |
| 位置   | http、server、location               |

默认缓存 HTTP 的 GET 和 HEAD 方法的请求资源，不缓存 POST 方法的请求资源。





## Nginx缓存设置案例

#### 需求分析

![1591959569463](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/1591959569463.png)



#### 步骤实现

**1.环境准备**

应用服务器的环境准备

（1）在192.168.200.146服务器上的tomcat的webapps下面添加一个js目录，并在js目录中添加一个jquery.js文件

（2）启动tomcat

```sh
cd /usr/local/tomcat/bin
./startup.sh
```

（3）访问服务器 A 进行测试

```http
http://192.168.200.146:8080/js/jquery.js
```



Nginx的环境准备

（1）准备服务器 B 完成 Nginx 的反向代理配置

```nginx
http{
	upstream backend{
		server 192.168.200.146:8080; # 服务器 A 地址
	}
	server {
		listen       8080;
        server_name  localhost;
        location / {
        	proxy_pass http://backend/js/;
        }
	}
}
```

（2）完成Nginx缓存配置



**2.添加Nginx缓存配置**

```nginx
http{
    # 开启缓存
    proxy_cache_path /usr/local/proxy_cache levels=2:1 keys_zone=bing:200m inactive=1d max_size=20g;
    upstream backend{
        server 192.168.200.146:8080;   # 服务器 A 的地址
    }
    server {
        listen       8080;     			# 监听 8080 端口
        server_name  localhost; 		# 监听 localhost 的IP
        location / {					# 监听包含 / 的请求
            proxy_cache itcast;    		# 开启 itcast 缓存区，和第 2 行的 keys_zone 对应
            proxy_cache_key itheima;  		# 缓存的 key 值，会被 MD5 解析成字符串用于生成缓存的目录，一般采用默认就行
            proxy_cache_min_uses 5; 	# 资源被访问 5 次后才会被缓存
            proxy_cache_valid 200 5d;	# 为 200 响应 URL 设置 5 天缓存时间
            proxy_cache_valid 404 30s;  # 为 404 的响应 URL 设置 30 秒缓存时间
            proxy_cache_valid any 1m;	# 为除了上方的任意响应 URL 设置 1 分钟缓存时间
            add_header nginx-cache "$upstream_cache_status";  # 将缓存的状态放到请求头里
            proxy_pass http://backend/js/;  # 代理 backend，将 /js/ 追加到 backend 模块里的地址后面
        }
    }
}
```



**3.测试是否缓存成功**

利用 `$upstream_cache_status` 的值在控制台(F12)查看是否缓存。

第一次访问 `192.168.200.113:8080/jquery.js`，如图：

![image](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/image3p1azxp6cdy0.webp)

因为第一次访问时，正在缓存，所以返回的请求头 MISS 是没有缓存成功。

第二次访问 `192.168.200.113:8080/jquery.js`，如图：

![image](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/image73w7kaxo8r00.webp)

HIT 代表成功缓存。



**4.测试 404 缓存时间**

测试 404 缓存时间，我们访问 `192.168.200.113:8080/jquery.js111`，它会返回 404 页面，并缓存 404 页面，当我们立即访问正确的 `192.168.200.113:8080/jquery.js`，它依然返回 404 页面，因为 `/jquery.js` 请求目前被缓存为 404，还没到 30 秒过期，等 30 秒后再访问，就成功了。





## Nginx缓存的清除

### 方式一:删除对应的缓存目录

假设缓存目录是 `/usr/local/proxy_cache/`

```sh
rm -rf /usr/local/proxy_cache/......
```

如果想删除某个缓存目录，就在后面加上目录名。如果想删除整个缓存目录，直接删除 `/usr/local/proxy_cache/` 即可。



### 方式二:使用第三方扩展模块

使用第三方扩展模块 `ngx_cache_purge` 进行删除缓存。

（1）下载`ngx_cache_purge`模块对应的资源包，并上传到服务器的 `/root/nginx/module/` 目录下。

```sh
ngx_cache_purge-2.3.tar.gz
```

（2）对资源文件进行解压缩

```sh
tar -zxf ngx_cache_purge-2.3.tar.gz
```

（3）修改文件夹名称为`purge`，方便后期配置

```sh
mv ngx_cache_purge-2.3 purge
```

（4）查询 Nginx 的配置参数 configure arguments，并拷贝出来

```sh
nginx -V
```

（5）进入 Nginx 的安装包目录，使用 ./configure 进行参数配置，记得加上 nginx -V 查询出来的 configure arguments 参数

```sh
./configure --add-module=/root/nginx/module/purge # 加上之前的 configure arguments 参数
```

（6）使用make进行编译

```
make
```

（7）将nginx安装目录的nginx二进制可执行文件备份

```sh
mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginxold
```

（8）将编译后的objs中的nginx拷贝到nginx的sbin目录下

```sh
cp objs/nginx /usr/local/nginx/sbin
```

（9）使用 `make upgrade` 进行升级，记得在安装包目录下执行

```sh
cd /opt/nginx/core/nginx-1.20.2

make upgrade
```

（10）在nginx配置文件中进行如下配置

```nginx
server{
	location ~/purge(/.*) {
        # 删除 缓存区 缓存key
        # 注意：这个移除缓存key 一定要与 保存key一致。注意：如果保存缓存key用$scheme$proxy_host$request_uri，移除缓存key也使用这个名字，那么移除缓存可能失败，详细的话 打个日志就知道了
		proxy_cache_purge itcast itheima;
	}
}
```

`proxy_cache_purge` 指令

| 语法                            | 默认值 | 位置                   |
| ------------------------------- | ------ | ---------------------- |
| proxy_cache_purge <cache> <key> | -      | http、server、location |

- `cache` 是 `proxy_cache`，详细内容看 [proxy_cache(opens new window)](https://notes.youngkbt.cn/nginx/cache-integration/#proxy-cache)
- `key` 是 `proxy_cache_key`，详细内容看 [proxy_cache_key(opens new window)](https://notes.youngkbt.cn/nginx/cache-integration/#proxy-cache-key)





## Nginx设置资源不缓存

前面咱们已经完成了Nginx作为web缓存服务器的使用。但是我们得思考一个问题：**不是所有的数据都适合进行缓存**。比如说对于一些经常发生变化的数据。如果进行缓存的话，就很容易出现用户访问到的数据不是服务器真实的数据。所以对于这些资源我们在缓存的过程中就需要进行过滤，不进行缓存。

Nginx也提供了这块的功能设置，需要使用到如下两个指令

- proxy_no_cache
- proxy_cache_bypass



### proxy_no_cache

该指令是用来**定义不将数据进行缓存的条件**，也就是不缓存指定的数据。

| 语法   | proxy_no_cache string ...; |
| ------ | -------------------------- |
| 默认值 | —                          |
| 位置   | http、server、location     |

可设置多个 string。

配置实例

```nginx
proxy_no_cache $cookie_nocache $arg_nocache $arg_comment;
```



### proxy_cache_bypass

该指令是用来**设置不从缓存中获取数据的条件**，也就是虽然缓存了指定的资源，但请求过来也不会去获取它，而是去服务器里获取资源。

| 语法   | proxy_cache_bypass string ...; |
| ------ | ------------------------------ |
| 默认值 | —                              |
| 位置   | http、server、location         |

可设置多个 string。

配置实例

```nginx
proxy_cache_bypass $cookie_nocache $arg_nocache $arg_comment; #也就是这里指定了3个变量 也就是指定了3个条件，这3个条件只要有一个不为空且不等于，则此条件成立。如果条件成立，就不会去拿缓存数据
```

上述两个指令都有一个指定的条件，这个条件可以是多个，**并且多个条件中至少有一个不为空且不等于「0」，则条件满足成立。**上面给的配置实例是从官方网站获取的，里面使用到了三个变量，分别是 `$cookie_nocache`、`$arg_nocache`、`$arg_comment`

> 所以，重点的是要知道，这几个条件如何设置，有啥用



### 常用不缓存变量

常用不缓存的三个变量分别为：

- `$cookie_nocache`
- `$arg_nocache`
- `$arg_comment`

这三个参数分别代表的含义是：

- `$cookie_nocache`：指的是当前请求的 cookie 中 key 为 nocache 的 value 值
- `$arg_nocache` 和 `$arg_comment`：指的是当前请求的参数中属性名为 nocache 和 comment 对应的属性值

案例演示下:

```nginx
log_format params $cookie_nocache | $arg_nocache | $arg_comment; #通过日志输出3个变量分别代表什么
server{
	listen	8081;
	server_name localhost;
	location /{
		access_log logs/access_params.log params;
		add_header Set-Cookie 'nocache=888'; # 将'nocache=888'添加到cookie中
		root html;
		index index.html;
	}
}
```

访问 `192.168.200.133:8081?nocache=999&comment=777`，然后去日志查看结果，如图所示：

![image](https://cdn.staticaly.com/gh/Sidney-Su/cartographic-bed@main/计算机/Nginx/day04/image695kmtpob840.webp)

以后访问的某一个资源如果不想缓存，在 URL 后面加入三个变量中的任意一个或多个即可，只要它们不为空或 0。

> ==注意：这三个变量推荐作为不缓存资源的条件，但并不是只能作为不缓存资源的条件。==





### 案例实现

设置不缓存资源的配置方案模板：

- 如果访问的是 js 文件，则不会缓存该 js 文件
- 如果 `$nocache` `$cookie_nocache` `$arg_nocache` `$arg_comment` 任意不为空或 0，则访问的资源不进行缓存

```nginx
server{
    listen	8080;
    server_name localhost;
    location / {
        if ($request_uri ~ /.*\.js$){ #如果访问的js文件，则不进行缓存 .代表任意字符 \.代表.
            set $arg_comment 1;
        }
        # 官方推荐两个都进行配置
        # 不进行缓存 一旦4个条件中有值且不为0，就不会进行缓存
        proxy_no_cache $nocache $cookie_nocache $arg_nocache $arg_comment;
        # 缓存但不从缓存中取数据
        proxy_cache_bypass $nocache $cookie_nocache $arg_nocache $arg_comment;
    }
}
```

为什么不会缓存 js 文件呢，看第 5 - 6 行代码。如果访问的文件是 js 文件，则设置 `$nocache` 为 1，只要它不为 0，则触发第 8 行代码，`proxy_no_cache` 后面的参数只要有一个不为空或 0，则访问的资源不进行缓存。